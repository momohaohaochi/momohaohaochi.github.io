---
title: MongoDB 的副本集（集群）
date: '2020-07-04 00:00:00'
tags:
- MSB
- Database
- MongoDB
- Java
---
# MongoDB 的副本集（集群）

MongoDB 中的副本集（复制集）是一组维护相同数据集的 mongod 进程。复制集提供冗余和高可用性，是所有生产部署的基础。**注意副本集只能提高读能力，不能提高写能力，如果要提高写能力，需要使用数据分片**

## 目的

冗余和数据可用性

副本集提供了数据的冗余，提高了数据的可用性。由于在不同的数据库服务器上有多个数据副本，副本集提供了一定程度的容错能力，防止单个数据库服务器的损失。

在某些情况下，复制可以提供更高的**读取能力**，因为客户端可以向不同的服务器发送读取操作。在不同的数据中心维护数据副本可以提高分布式应用的数据定位和可用性。您还可以为专用目的维护额外的副本，如灾难恢复，备份。

总结起来：

1. 高可用
2. 数据分发：不通地区都放置服务器，可以提高读写速度
3. 读写分离：提升读的能力（写能力不仅没有提升，反而下降了）
4. 灾难恢复

## 副本集部署架构

复制集是一组维护相同数据集的 mongod 实例。一个复制集包含几个数据承载节点和可选的一个仲裁节点（投票节点）。在数据承载节点中，一个且仅有一个成员被视为主节点，而其他节点被视为从节点。

- 一个副本集最多可以有 50 个成员，但只有 7 个投票成员
- 副本集必须有一个主节点
- 只有主节点能写数据，所有节点都能读数据，但默认只从主节点进行读取，从节点不读取，可配置 Read Preference 更改
- 不推荐使用投票节点（Arbiter）

**通常使用一主两从的方式**

### 节点分类

#### 主节点（Primary）

主节点接收所有的写操作。一个副本集只能有一个主节点，primary 将其数据集的所有变化记录在其操作日志中，即 oplog

#### 从节点（Secondary）

从节点复制主节点的 oplog，并将其操作应用于自己的数据集。如果主节点不可用，符合条件的从节点进行选举，产生新的主节点。

#### 仲裁节点（Arbiter）

也叫投票节点。在某些情况下（例如只有一个主节点和一个从节点，但由于成本限制而无法再增加一个从节点），可以选择将一个 mongod 实例作为仲裁者添加到副本集中。仲裁者参与选举，但不持有数据（即不提供数据冗余）。

## Oplog 日志介绍

Oplog（operation log）是一个特殊的集合，记录所有对数据库修改（新增，修改，删除）行为的日志，这些日志被称为 Oplog

MongoDB 在主节点上应用数据库的操作，然后记录到 oplog 上，其他从节点通过异步的方式复制这些日志，所有从节点都包含主节点 oplog 的副本

为了方便复制，所有副本集成员都会向所有其他成员发送心跳（ping）。任何从节点，都可以从其他成员那里导入 oplog 日志

oplog 日志是幂等的，也就是说 oplog 作用在目标数据库上的行为，不管是一次还是多次，效果都是一样的

oplog 日志是有大小的，默认是物理磁盘的 5%。通过 `rs.printSlaveReplicationInfo()` 查看当前集群的 oplog 大小

通常情况下 oplog 增长速度等同于主节点插入新文档速度，一旦超过阈值大小，旧的日志会被覆盖，所以一般情况下，oplog 日志的大小要足够 24 小时新增的数量，一般保证 72 小时。如果出现从节点无法同步主节点 oplog 情况，可以考虑手动同步数据，mongodb 提供两种数据同步策略：

1. 初始同步
2. 复制同步

## 数据同步流程

为了保证副本及的数据实时同步，从节点从其他成员那里同步数据，MongoDB 提供了两种数据同步方式：

1. 初始同步
2. 复制

### 初始同步

从副本集中的一个成员那里复制全量的数据。例如在集群中新增一个 mongodb 节点，该节点第一次同步就是初始同步

### 复制

从节点在初始化同步后连续复制数据。从节点会从提供源数据的节点复制 oplog 操作并恢复数据，根据 ping 时间和其他成员复制状态的更改，从节点可以根据需要自动更改它的同步

## 选举机制

当主节点出现问题时，会从从节点中选举出一个节点作为新的主节点

**选举机制保证故障恢复**

- 具有投票权的节点之间两两互相发送心跳
- 当 5 次心跳未收到时判断为节点失联
- 如果主节点失联，从节点会发起选举，选出新的主节点
- 如果从节点失联，不发生新的选举
- 选举算法：RAFT 一致性算法。成功的必要条件是大多数投票节点存活
- 副本集中最多可以有 50 个节点，但具有投票权的节点最多有 7 个

**影响选举结果的因素**

- 整个集群必须有大多数节点存活
- 被选举为主节点的节点需要具备的条件
  - 能够与多数节点建立连接
  - 具有较新的 oplog
  - 具有较高的优先级

容错率

| 成员数量 | 选举需要的大多数数量（一半 +1） | 默认容错数量 |
| -------- | ----------------------------- | ------------ |
| 3        | 2                             | 1            |
| 4        | 3                             | 1            |
| 5        | 3                             | 2            |
| 6        | 4                             | 2            |

3 个节点集群和 4 个节点集群的容错数量都是 1 台机器，所以用 3 个机器可以获得与 4 个节点相同的容错，同时能够节省资源。因此说，**推荐使用奇数个实例进行集群**。

**高级选项**

一般情况下，搭建副本集的时候，可以不用额外的配置，如果想搭建更复杂高级的副本集，可以参考如下配置：

- 配置是否具有投票权：参数 v，有投票权才能参与投票
- 配置优先级：参数 priority，数字类型，数值越大，优先级越大，就越容易成为主节点
- 配置是否隐藏：参数 hidden，复制数据，但对应用不可见。隐藏节点可以具有投票权，但是优先级必须为 0
- 配置复制数据的延迟时间：参数 slaveDelay，复制 n 秒之前的数据

**注意事项**

1. 任何一个从节点都可能成为主节点，所以主从节点的硬件配置应该一样，以防止从节点升级为主节点后，扛不住压力
2. 各个节点应该保证不会同时宕机，一般多机房多中心部署，即硬件环境需要隔离
3. 副本集当中 MongoDB 版本必须一致，防止不可预知的问题发生
4. 增加节点，不会增加系统写性能。从节点主要用于备份，容灾，增加读性能

## 集群搭建

1. 启动三台虚拟机，主机名和 IP 设置如下

   | 主机名    | IP             | 类型   |
   | --------- | -------------- | ------ |
   | ubuntu-01 | 192.168.56.101 | 主节点 |
   | ubuntu-02 | 192.168.56.102 | 从节点 |
   | ubuntu-03 | 192.168.56.103 | 从节点 |

   修改主机名称

   ```shell
   sudo hostnamectl set-hostname new-hostname
   ```

2. 修改 /etc/hosts 文件

   ```shell
   192.168.56.101 ubuntu-01
   192.168.56.102 ubuntu-02
   192.168.56.103 ubuntu-03
   ```

3. 在 3 台机器上分别创建 mongodb 的 data，conf，logs 文件夹

   ```shell
   mkdir -p /path/to/mongodb/data
   mkdir -p /path/to/mongodb/conf
   mkdir -p /path/to/mongodb/logs
   ```

4. 解压 mongodb

   ```shell
   tar -zxvf mongodb-linux-x86_64-ubuntu2004-4.4.5.tgz -c /path/to/mongodb
   ```

5. 在 conf 目录下添加 mongodb 的配置文件：mongodb.yaml

   ```yaml
   systemLog:
     destination: file
     path: "/path/to/mongodb/logs/mongo.log"
     logAppend: true
   storage:
     dbPath: "/path/to/mongodb/data"
     journal:
       enabled: true
   processManagement:
     fork: true
     pidFilePath: "/path/to/mongodb/logs/mongod.pid"
   net:
     bindIp: 0.0.0.0
     port: 27017
   # 其他配置与单节点相似，只有此处需要额外添加复制集的配置
   replication:
     # 设置复制集的名称，所有节点要相同
     replSetName: rs0
   ```

6. 分别启动 mongod 服务

   ```shell
   mongod -f /path/to/mongodb/conf/mongodb.yaml
   ```

7. 登陆主节点

   ```shell
   mongo --host ubuntu-01 --port 27017
   ```

8. 初始化主节点的副本集

   ```mongodb
   rs.initiate()
   ```

9. 在主节点中添加从节点，**此处推荐使用主机名进行搭建，使用 IP 可能会出问题**

   ```mongodb
   rs.add("ubuntu-02:27017")
   rs.add("ubuntu-03:27017")
   ```
   
   此时，mongodb 的主从配置已经完成了，在主节点中插入一条数据，在从节点使用命令行进行查询，会报异常，但是使用 MongoDBCompass 是可以连接到从节点，并且可以发现数据已经同步了的。是因为 mongodb 的服务端集群已经搭建成功，但是客户端还需要一些配置，MongoDBCompass 已经对其进行了配置，所以可以成功，命令行的 client 还需要执行下方命令，才可以查看到数据。

10. 在所有从节点上执行如下命令

    ```mongodb
    rs.secondaryOk()
    ```

    此时，通过命令行方式就可以查询到主节点上的数据了

### 集群管理相关命令

1. 查看集群状态：`rs.status()`
2. 查看集群配置：`rs.conf()`

3. 修改节点的优先级（需要在主节点上执行下方命令）

   ```mongodb
   # 生成一个临时变量 conf
   conf=rs.conf()
   # 将角标为 1 的节点优先级调高为 2（角标从 0 开始，优先级高的，重新选举后会变成主节点）
   conf.members[1].priority=2
   # 重新加载配置，此时会触发重新选举
   rs.reconfig(conf)
   ```

   应用场景：比如在北京和四川都有 mongodb 的节点，默认的主节点是在北京，在该主节点宕机后，不希望将主节点迁移到四川，就可以将北京的节点的优先级同时调高，例如北京的都是 2，四川的都是 1，这样主节点宕机后，依旧会从北京的节点中选举出新的主节点。

### 模拟测试

#### 主节点宕机

1. 模拟主节点宕机，手动 kill 掉主节点
2. 可以发现某个从节点会变成主节点
3. 在新的主节点中插入新的数据
4. 手动启动之前的主节点
5. 稍后，之前的主节点会变为主节点，同时可以查询到第 3 步中插入的新数据

主节点向 oplog 中写日志的速度大于从节点同步的速度，主节点突然宕机，就会丢数据。

#### 从节点宕机

1. 模拟从节点宕机，手动 kill 掉一个从节点

2. 在主节点中插入新的数据

3. 手动重启宕机的从节点

4. 查询从节点中的数据

   此时会报错，所以需要重新设置一下 `rs.secondaryOk()`

5. 之后从节点即可读取到相应的数据

